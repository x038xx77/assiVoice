import { Telegraf, session } from "telegraf";
import { message } from 'telegraf/filters';
import { countAndTrackTokens, getTotalTokens } from './tokenCounter.js';
import { code } from 'telegraf/format';
import config from 'config';
import { ogg } from './ogg.js';
import { openai } from './openai.js';


const INITIAL_SSESION = {
    messages:[],
}
const bot = new Telegraf(config.get('TELEGRAM_TOKEN'))
bot.use(session())

// TEST
// const str = `Many words map to one token, but some don't: indivisible.
const str = `ÐŸÑ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ Ð¸ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒ`
// Unicode characters like emojis may be split into many tokens containing the underlying bytes: ðŸ¤šðŸ¾
// Sequences of characters commonly found next to each other may be grouped together: 1234567890`
// const encodedAnswer = (encode(str)).length
// console.log('Encoded this string looks like: ', encodedAnswer)

const tokenCount = countAndTrackTokens(str, 'query');

console.log(`Ð’Ð°Ñˆ Ð·Ð°Ð¿Ñ€Ð¾Ñ: ${str}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ ÐºÐ¾Ð»-Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ: ${tokenCount}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð²ÑÐµÑ… Ð·Ð°Ð¿Ñ€Ð¾ÑÐ¾Ð²: ${getTotalTokens('query')}`);

// END TEST Count Tokens GPT


bot.command('new', async (ctx)=>{
    ctx.session = INITIAL_SSESION
    await ctx.reply('Ð¶Ð´Ñƒ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ Ð¸Ð»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ')
})

bot.command('start', async (ctx)=>{
    ctx.session = INITIAL_SSESION
    await ctx.reply('Ð¶Ð´Ñƒ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð³Ð¾ Ð¸Ð»Ð¸ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ð¾Ð³Ð¾ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ')
})

// VOICE
bot.on(message('voice'), async ctx => {
    ctx.session ??= INITIAL_SSESION
    try {
        await ctx.reply(code('Ð¡Ð¾Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð½ÑÐ», Ð¶Ð´Ñƒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ ÑÐµÑ€Ð²ÐµÑ€Ð°...'))
        const link = await ctx.telegram.getFileLink(ctx.message.voice.file_id)
        const userId = String(ctx.message.from.id)
        const oggPath = await ogg.create(link.href, userId);
        const mp3Path = await ogg.toMp3(oggPath, userId);
        const text = await openai.transcription(mp3Path);  
        
        const tokensGPT3Query = countAndTrackTokens(text, 'query');
        await ctx.reply(code(`Ð’Ð°Ñˆ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ: ${text}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ ÐºÐ¾Ð»-Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ: ${tokensGPT3Query}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð², ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ Ð²ÑÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹: ${getTotalTokens('query')}`))
        

        ctx.session.messages.push({role: openai.roles.USER, content:text}) // system:promt GPT
        const response = await openai.chat(ctx.session.messages);
        ctx.session.messages.push({role: openai.roles.ASSISTANT, content:response.content}) // system:promt GPT

        const tokensGPT3Request = countAndTrackTokens(response.content, 'request');

        await ctx.reply(code(`Ð’Ð°Ñˆ Ð³Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚: ${response.content}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ ÐºÐ¾Ð»-Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ: ${tokensGPT3Request}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð², ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ Ð²ÑÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹: ${getTotalTokens('request')}`));


    } catch (e) {
        console.log("Error while Voice message: ", e.message)      
    }    
});

// TEXT
bot.on(message('text'), async ctx => {
    ctx.session ??= INITIAL_SSESION
    try {
        await ctx.reply(code('Ð¡Ð¾Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ð¿Ñ€Ð¸Ð½ÑÐ», Ð¶Ð´Ñƒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¾Ñ‚ ÑÐµÑ€Ð²ÐµÑ€Ð°...'))      
        ctx.session.messages.push({role: openai.roles.USER, content:ctx.message.text}) // system:promt GPT  
        
        const tokensGPT3Query = countAndTrackTokens(ctx.message.text, 'query');
        await ctx.reply(code(`Ð’Ð°Ñˆ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð·Ð°Ð¿Ñ€Ð¾Ñ: ${ctx.message.text}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ ÐºÐ¾Ð»-Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ: ${tokensGPT3Query}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð², ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ Ð²ÑÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹: ${getTotalTokens('query')}`))



        const response = await openai.chat(ctx.session.messages);        
        ctx.session.messages.push({role: openai.roles.ASSISTANT, content:response.content}) // system:promt GPT

        const tokensGPT3Request = countAndTrackTokens(response.content, 'request');    

        await ctx.reply(code(`Ð’Ð°Ñˆ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²Ñ‹Ð¹ Ð¾Ñ‚Ð²ÐµÑ‚: ${response.content}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ ÐºÐ¾Ð»-Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð² Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ: ${tokensGPT3Request}\n Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¾ Ð¾Ð±Ñ‰ÐµÐµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð², ÑƒÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°Ñ Ð²ÑÐµ Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹: ${getTotalTokens('request')}`));

    } catch (e) {
        console.log("Error while Voice message: ", e.message)      
    }    
});

bot.launch()
process.once('SIGINT', () => bot.stop('SIGINT'))
process.once('SIGTERM', () => bot.stop('SIGTERM'))
